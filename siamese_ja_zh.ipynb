{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Siamese_XLM_RoBERTa_ja_zh_wmt21.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4ddb4c518625475cb2992a8ba4026b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea5cb9ab00434308b4ce22f25eb89233",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b346672f1c9644bfbeb0eb61116bed7d",
              "IPY_MODEL_a06f65fad4cd44af8e45c9ee680815db"
            ]
          }
        },
        "ea5cb9ab00434308b4ce22f25eb89233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b346672f1c9644bfbeb0eb61116bed7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_31e2a2644c1d4ba4825f9c6372203d22",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 624,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 624,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1f6f48dbfb84e8cbb6fd1d3a15a332d"
          }
        },
        "a06f65fad4cd44af8e45c9ee680815db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1bc1f5029bbe45ef85a14de1e87de886",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 624/624 [00:00&lt;00:00, 1.05kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9e700da67614137a8801d3d55925465"
          }
        },
        "31e2a2644c1d4ba4825f9c6372203d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1f6f48dbfb84e8cbb6fd1d3a15a332d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bc1f5029bbe45ef85a14de1e87de886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9e700da67614137a8801d3d55925465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8660c8b8100f4480bee53279ebbd1f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_19137ca3f4fd4b0ca4c69f7770a915a6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e4a509729faa480a84d961e0c4d19c56",
              "IPY_MODEL_8bc5a269714d4ca1b8bb24178738309f"
            ]
          }
        },
        "19137ca3f4fd4b0ca4c69f7770a915a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4a509729faa480a84d961e0c4d19c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a9fb235d84fe40788539dfad041c469d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d971ece6b4d341aabc96ae3e1ca47304"
          }
        },
        "8bc5a269714d4ca1b8bb24178738309f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e12d226a1764ec79b1e55f010503a41",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110k/110k [00:00&lt;00:00, 514kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a244873692e403c9225bef7d20a94d9"
          }
        },
        "a9fb235d84fe40788539dfad041c469d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d971ece6b4d341aabc96ae3e1ca47304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e12d226a1764ec79b1e55f010503a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a244873692e403c9225bef7d20a94d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12c505343133406f877f9651d1b3a320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32a66474599b475dbc249765caf49106",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f74cad407a646eaa8b3ebc27a755e50",
              "IPY_MODEL_93d5331bedd84e6abebccdce362bc9d4"
            ]
          }
        },
        "32a66474599b475dbc249765caf49106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f74cad407a646eaa8b3ebc27a755e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_216818fc6ca34f76a3028514f1537f27",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 411577189,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 411577189,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1933c73861074406a0b45020f7dbbb0b"
          }
        },
        "93d5331bedd84e6abebccdce362bc9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c1267be3b8c44548a42c3d82d3d65be2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 412M/412M [00:11&lt;00:00, 35.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a692c030ca14964a39de2dda5ceaa9e"
          }
        },
        "216818fc6ca34f76a3028514f1537f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1933c73861074406a0b45020f7dbbb0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1267be3b8c44548a42c3d82d3d65be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a692c030ca14964a39de2dda5ceaa9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haeggee/error-detection-mt/blob/main/siamese_ja_zh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuLR0BMJhIub"
      },
      "source": [
        "# Siamese XLM RoBERTa for sentence pair classification in English-Japanese and English-Chinese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZIHhCYNhN-H"
      },
      "source": [
        "#### Sections\n",
        "\n",
        "1. [Installation of libraries and imports](#section01)\n",
        "\n",
        "2. [Classes and functions](#section02)\n",
        "\n",
        "3. [English-Japanese](#section03)\n",
        "\n",
        "4. [English-Chinese](#section04)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIv7rF4V6lyE"
      },
      "source": [
        "## Installation of libraries and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42-lJ1u9IHT6"
      },
      "source": [
        "!pip install datasets==1.0.1 -q\n",
        "!pip install transformers==3.1.0 -q\n",
        "!pip install pickle5 -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l70xKUSdq35O"
      },
      "source": [
        "!pip install fugashi -q \n",
        "!pip install ipadic -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE_TpNaSZQ5n",
        "outputId": "a99ed602-a10b-45c6-bfc6-ab821dc569fb"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle5 as pickle\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM, AdamW, get_linear_schedule_with_warmup\n",
        "from datasets import load_dataset, load_metric\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version 1.9.0+cu102 available.\n",
            "TensorFlow version 2.5.0 available.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF8IWdEowPP-",
        "outputId": "7b26e645-72b9-4d3c-9076-9ba1ba257f4c"
      },
      "source": [
        "# Check that we are using 100% of GPU memory footprint support libraries/code\n",
        "# from https://github.com/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip -q install gputil\n",
        "!pip -q install psutil\n",
        "!pip -q install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.5 GB  | Proc size: 597.6 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoGB7Arrwb4A"
      },
      "source": [
        "\n",
        "In case GPU utilisation (Util) is not at 0%, you can uncomment and run the following line to kill all processes to get the full GPU afterwards. Make sure to comment out the line again to not constantly crash the notebook on purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNdVkubWwdiD"
      },
      "source": [
        "#!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyjQfhEda6HC"
      },
      "source": [
        "#!unzip dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWJfh6DV7CB5"
      },
      "source": [
        "## Classes and functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61cjZY6kJir9"
      },
      "source": [
        "def dataset_splitting(lang_pair):\n",
        "  filename_train = \"dataset/wmt21_multi_train.pkl\" \n",
        "  dataset_train = pickle.load(open(filename_train,'rb'))\n",
        "  filename_dev = \"dataset/wmt21_multi_dev.pkl\" \n",
        "  dataset_dev = pickle.load(open(filename_dev, 'rb'))\n",
        "  dataset_train = dataset_train[dataset_train['language_pair']==lang_pair]\n",
        "  dataset_dev = dataset_dev[dataset_dev['language_pair']==lang_pair]\n",
        "  df_train, df_val = train_test_split(dataset_train, test_size = 0.05, random_state=42)  # split the original training data for validation\n",
        "  df_test = dataset_dev\n",
        "\n",
        "  df_train = df_train.reset_index(drop=True)\n",
        "  df_val = df_val.reset_index(drop=True)\n",
        "  df_test = df_test.reset_index(drop=True)\n",
        "  print(\"Training set: \", df_train.shape)\n",
        "  print(\"Validation set: \", df_val.shape)\n",
        "  print(\"Test set:\", df_test.shape)\n",
        "  return df_train, df_val, df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc1GQh7yEm4C"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, maxlen, bert_model_src='bert-base-uncased', bert_model_mt='cl-tohoku/bert-base-japanese', with_labels=True):\n",
        "\n",
        "        self.data = data  # pandas dataframe\n",
        "        #Initialize the tokenizer\n",
        "        self.tokenizer_src = AutoTokenizer.from_pretrained(bert_model_src)  \n",
        "        self.tokenizer_mt = AutoTokenizer.from_pretrained(bert_model_mt)\n",
        "        self.maxlen = maxlen\n",
        "        self.with_labels = with_labels \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # Selecting sentence1 and sentence2 at the specified index in the data frame\n",
        "        sent_src = str(self.data.loc[index, 'src'])\n",
        "        sent_mt = str(self.data.loc[index, 'mt'])\n",
        "        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n",
        "        encoded_pair_src = self.tokenizer_src(sent_src, \n",
        "                                      padding='max_length',  # Pad to max_length\n",
        "                                      truncation=True,  # Truncate to max_length\n",
        "                                      max_length=self.maxlen,  \n",
        "                                      return_tensors='pt')  # Return torch.Tensor objects\n",
        "        encoded_pair_mt = self.tokenizer_mt(sent_mt, padding='max_length',\n",
        "                                            truncation=True, max_length=self.maxlen,\n",
        "                                            return_tensors='pt')\n",
        "        token_ids = [encoded_pair_src['input_ids'].squeeze(0), encoded_pair_mt['input_ids'].squeeze(0)]  # tensor of token ids\n",
        "        attn_masks = [encoded_pair_src['attention_mask'].squeeze(0), encoded_pair_mt['attention_mask'].squeeze(0)]  # binary tensor with \"0\" for padded values and \"1\" for the other values                                                          \n",
        "        token_type_ids = [encoded_pair_src['token_type_ids'].squeeze(0), encoded_pair_mt['token_type_ids'].squeeze(0)]\n",
        "        # xml-roberta doesn't make use of a token type id\n",
        "        if self.with_labels:  # True if the dataset has labels\n",
        "            label = int(self.data.loc[index, 'critical'])\n",
        "            return token_ids, attn_masks, token_type_ids, label  \n",
        "        else:\n",
        "            return token_ids, attn_masks, token_type_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm0lAXvTZChm"
      },
      "source": [
        "class SentencePairClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, bert_model_src='bert-base-uncased', bert_model_mt='cl-tohoku/bert-base-japanese',freeze_bert=False):\n",
        "        super(SentencePairClassifier, self).__init__()\n",
        "        #  Instantiating BERT-based model object\n",
        "        self.bert_layer_src = AutoModel.from_pretrained(bert_model_src)\n",
        "        self.bert_layer_mt = AutoModel.from_pretrained(bert_model_mt)\n",
        "\n",
        "        #  Fix the hidden-state size of the encoder outputs (If you want to add other pre-trained models here, search for the encoder output size)\n",
        "        if bert_model_src == \"bert-base-uncased\":\n",
        "          hidden_size_src = 768\n",
        "        else:\n",
        "          print(\"Look for the hidden-state size of the src model\")\n",
        "\n",
        "        if bert_model_mt == \"cl-tohoku/bert-base-japanese\":\n",
        "            hidden_size_mt = 768\n",
        "        elif bert_model_mt == \"bert-base-chinese\":\n",
        "            hidden_size_mt = 768\n",
        "        else:\n",
        "          print(\"Look for the hidden-state size of the mt model\")\n",
        "        \n",
        "\n",
        "        # Freeze bert layers and only train the classification layer weights\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_layer_src.parameters():\n",
        "                p.requires_grad = False\n",
        "            for p in self.bert_layer_mt.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        # Classification layer\n",
        "        self.dropout_src = nn.Dropout(p=0.2)\n",
        "        self.dropout_mt = nn.Dropout(p=0.2)\n",
        "        self.clf = nn.Linear(hidden_size_src+hidden_size_mt, 1)\n",
        "  \n",
        "    @autocast()  # run in mixed precision\n",
        "    def forward(self, input_ids, attn_masks, token_type_ids):\n",
        "        '''\n",
        "        Inputs:\n",
        "            -input_ids : Tensor  containing token ids\n",
        "            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values\n",
        "            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2\n",
        "        '''\n",
        "\n",
        "        # Feeding the inputs to the BERT-based model to obtain contextualized representations\n",
        "        cont_reps_src, pooler_output_src = self.bert_layer_src(input_ids[0], attn_masks[0], token_type_ids[0])\n",
        "        \n",
        "        cont_reps_mt, pooler_output_mt = self.bert_layer_mt(input_ids[1], attn_masks[1], token_type_ids[1])\n",
        "\n",
        "        \"\"\"\n",
        "        # Feeding to the classifier layer the last layer hidden-state of\n",
        "        the [CLS] token further processed by a\n",
        "        Linear Layer and a Tanh activation.\n",
        "        The Linear layer weights were trained from the sentence order\n",
        "        prediction (ALBERT) or next sentence prediction (BERT)\n",
        "        objective during pre-training.\n",
        "        \"\"\"\n",
        "        logits = self.clf(torch.cat((self.dropout_src(pooler_output_src), self.dropout_mt(pooler_output_mt)),1))\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SrSNNYTjwe8"
      },
      "source": [
        "def set_seed(seed):\n",
        "    \"\"\" Set all seeds to make results reproducible \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    \n",
        "\n",
        "def evaluate_loss(net, device, criterion, dataloader):\n",
        "    net.eval()\n",
        "\n",
        "    mean_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(dataloader)):\n",
        "            labels = labels.to(device)\n",
        "            seq = [seq[0].to(device), seq[1].to(device)]\n",
        "            attn_masks = [attn_masks[0].to(device), attn_masks[1].to(device)]\n",
        "            token_type_ids = [token_type_ids[0].to(device), token_type_ids[1].to(device)]\n",
        "            logits = net(seq, attn_masks, token_type_ids)\n",
        "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
        "            count += 1\n",
        "\n",
        "    return mean_loss / count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl-rhuWsrg01",
        "outputId": "0d2119a6-4fd8-477d-8745-6a11d76b6a16"
      },
      "source": [
        "print(\"Creation of the models' folder...\")\n",
        "!mkdir -p models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creation of the models' folder...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-o6KyaFkU5u"
      },
      "source": [
        "def train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate):\n",
        "\n",
        "    best_loss = np.Inf\n",
        "    best_ep = 1\n",
        "    nb_iterations = len(train_loader)\n",
        "    print_every = nb_iterations // 5  # print the training loss 5 times per epoch\n",
        "    iters = []\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    for ep in range(epochs):\n",
        "\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(train_loader)):\n",
        "\n",
        "            # Converting to cuda tensors\n",
        "\n",
        "            labels = labels.to(device)\n",
        "            seq = [seq[0].to(device), seq[1].to(device)]\n",
        "            attn_masks = [attn_masks[0].to(device), attn_masks[1].to(device)]\n",
        "            token_type_ids = [token_type_ids[0].to(device), token_type_ids[1].to(device)]\n",
        "            # Enables autocasting for the forward pass (model + loss)\n",
        "            with autocast():\n",
        "                # Obtaining the logits from the model\n",
        "                logits = net(seq, attn_masks, token_type_ids)\n",
        "                # Computing loss\n",
        "                loss = criterion(logits.squeeze(-1), labels.float())\n",
        "                loss = loss / iters_to_accumulate  # Normalize the loss because it is averaged\n",
        "            # Backpropagating the gradients\n",
        "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (it + 1) % iters_to_accumulate == 0:\n",
        "                # Optimization step\n",
        "                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "                # If these gradients do not contain infs or NaNs, opti.step() is then called,\n",
        "                # otherwise, opti.step() is skipped.\n",
        "                scaler.step(opti)\n",
        "                # Updates the scale for next iteration.\n",
        "                scaler.update()\n",
        "                # Adjust the learning rate based on the number of iterations.\n",
        "                lr_scheduler.step()\n",
        "                # Clear gradients\n",
        "                opti.zero_grad()\n",
        "\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if (it + 1) % print_every == 0:  # Print training loss information\n",
        "                print()\n",
        "                print(\"Iteration {}/{} of epoch {} complete. Loss : {} \"\n",
        "                      .format(it+1, nb_iterations, ep+1, running_loss / print_every))\n",
        "\n",
        "                running_loss = 0.0\n",
        "\n",
        "\n",
        "        val_loss = evaluate_loss(net, device, criterion, val_loader)  # Compute validation loss\n",
        "        print()\n",
        "        print(\"Epoch {} complete! Validation Loss : {}\".format(ep+1, val_loss))\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            print(\"Best validation loss improved from {} to {}\".format(best_loss, val_loss))\n",
        "            print()\n",
        "            net_copy = copy.deepcopy(net)  # save a copy of the model\n",
        "            best_loss = val_loss\n",
        "            best_ep = ep + 1\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    # Saving the model\n",
        "    path_to_model='models/{}_lr_{}_val_loss_{}_ep_{}.pt'.format(model_name, lr, round(best_loss, 5), best_ep)\n",
        "    torch.save(net_copy.state_dict(), path_to_model)\n",
        "    print(\"The model has been saved in {}\".format(path_to_model))\n",
        "\n",
        "    del loss\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAfbt0FjkCfM",
        "outputId": "9302b77b-64b7-4cfc-f8ef-c9df84c06c6f"
      },
      "source": [
        "print(\"Creation of the results' folder...\")\n",
        "!mkdir -p results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creation of the results' folder...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3r8_npVf30D"
      },
      "source": [
        "def get_probs_from_logits(logits):\n",
        "    \"\"\"\n",
        "    Converts a tensor of logits into an array of probabilities by applying the sigmoid function\n",
        "    \"\"\"\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "    return probs.detach().cpu().numpy()\n",
        "\n",
        "def test_prediction(net, device, dataloader, with_labels=True, result_file=\"results/output.txt\"):\n",
        "    \"\"\"\n",
        "    Predict the probabilities on a dataset with or without labels and print the result in a file\n",
        "    \"\"\"\n",
        "    net.eval()\n",
        "    w = open(result_file, 'w')\n",
        "    probs_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if with_labels:\n",
        "            for seq, attn_masks, token_type_ids, _ in tqdm(dataloader):\n",
        "                seq = [seq[0].to(device), seq[1].to(device)]\n",
        "                attn_masks = [attn_masks[0].to(device), attn_masks[1].to(device)]\n",
        "                token_type_ids = [token_type_ids[0].to(device), token_type_ids[1].to(device)]\n",
        "                logits = net(seq, attn_masks, token_type_ids)\n",
        "                probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n",
        "                probs_all += probs.tolist()\n",
        "        else:\n",
        "            for seq, attn_masks, token_type_ids in tqdm(dataloader):\n",
        "                seq = [seq[0].to(device), seq[1].to(device)]\n",
        "                attn_masks = [attn_masks[0].to(device), attn_masks[1].to(device)]\n",
        "                token_type_ids = [token_type_ids[0].to(device), token_type_ids[1].to(device)]\n",
        "                logits = net(seq, attn_masks, token_type_ids)\n",
        "                probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n",
        "                probs_all += probs.tolist()\n",
        "\n",
        "    w.writelines(str(prob)+'\\n' for prob in probs_all)\n",
        "    w.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoCmkgjlheb1"
      },
      "source": [
        "def evaluate_pred_test(labels_test, preds_test):\n",
        "  accuracy = accuracy_score(labels_test, preds_test)\n",
        "  bac = balanced_accuracy_score(labels_test, preds_test, adjusted=True)\n",
        "  f1 = f1_score(labels_test, preds_test)\n",
        "  precision = precision_score(labels_test, preds_test)\n",
        "  recall = recall_score(labels_test, preds_test)\n",
        "  cnf = confusion_matrix(labels_test, preds_test)\n",
        "  print(\"-----Evaluation-----\")\n",
        "  if cnf.shape == (2,2):\n",
        "    print(\"TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}\".format(tp=cnf[1][1], tn=cnf[0][0], fp=cnf[0][1], fn=cnf[1][0]))\n",
        "    print(\"F1: \", f1)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"Recall: \", recall)\n",
        "  print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8H7Gp_t9JiQ"
      },
      "source": [
        "def get_pred_from_prob(labels_test, probs_test):\n",
        "# choose threshold: according to precision-recall\n",
        "  from sklearn.metrics import precision_recall_curve\n",
        "  precision, recall, thresholds = precision_recall_curve(labels_test, probs_test)\n",
        "  fscore = (2 * precision * recall) / (precision + recall)\n",
        "  # locate the index of the largest f score\n",
        "  ix = np.argmax(fscore)\n",
        "  print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
        "  threshold = thresholds[ix]\n",
        "  preds_test = (probs_test>=threshold).astype('uint8')\n",
        "  return preds_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX0d2M1gG8w8"
      },
      "source": [
        "# For English-Japanese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpKx43Iq6znw"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwYB5I82J35H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fca1682-e1bb-4c88-a2b8-87781989e6e5"
      },
      "source": [
        "df_train, df_val, df_test = dataset_splitting('en-ja')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set:  (7274, 7)\n",
            "Validation set:  (383, 7)\n",
            "Test set: (999, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "irj7itV0UCF_",
        "outputId": "0dc39b96-ee15-4eb8-ba4f-4cf3d000e7b4"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>src</th>\n",
              "      <th>mt</th>\n",
              "      <th>list_scores</th>\n",
              "      <th>avg_scores</th>\n",
              "      <th>critical</th>\n",
              "      <th>language_pair</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4103</td>\n",
              "      <td>All I did to Knives and Pens was change a capi...</td>\n",
              "      <td>Knives and Pens に し た の は 、 大 文字 を 小 文字 に 変え る...</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0</td>\n",
              "      <td>en-ja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>613</td>\n",
              "      <td>Quick, tell someone with real power to block m...</td>\n",
              "      <td>急 い で 、 本物 の 力 の あ る 人 に これ から 私 を ブロック する よう ...</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0</td>\n",
              "      <td>en-ja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6751</td>\n",
              "      <td>Hey asshole, she's 18 years old. The briefing ...</td>\n",
              "      <td>ねえ お前 、 彼女 は 18 歳 だ ブリーフィング で 述べ た 。</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0</td>\n",
              "      <td>en-ja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6067</td>\n",
              "      <td>Anyone familiar at all with this article (by M...</td>\n",
              "      <td>この 記事 に 全く 慣れ て い る 人 ( マンゴー に よ る ) - アタチュルク ...</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0</td>\n",
              "      <td>en-ja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7436</td>\n",
              "      <td>how it is, bad enough that I can't simply remo...</td>\n",
              "      <td>メロディック ・ デス ・ メタル の 部分 を 削除 する こと は でき ま せ ん 。</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0</td>\n",
              "      <td>en-ja</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ... language_pair\n",
              "0  4103  ...         en-ja\n",
              "1   613  ...         en-ja\n",
              "2  6751  ...         en-ja\n",
              "3  6067  ...         en-ja\n",
              "4  7436  ...         en-ja\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFy9kQ2-SvQ2"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6bzDp4FreS6"
      },
      "source": [
        "model_name = \"japanese\"\n",
        "bert_model_src = \"bert-base-uncased\" #english bert model\n",
        "bert_model_mt = \"cl-tohoku/bert-base-japanese\" #japanese bert model\n",
        "freeze_bert = False  # if True, freeze the encoder weights and only update the classification layer weights\n",
        "maxlen = 128  # 75% below\n",
        "bs = 12  # batch size\n",
        "iters_to_accumulate = 2  # the gradient accumulation adds gradients over an effective batch of size : bs * iters_to_accumulate. If set to \"1\", you get the usual batch size\n",
        "lr = 1e-5 # learning rate\n",
        "epochs = 5  # number of training epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBEB7_46bkfz",
        "outputId": "2d60c467-3c7c-42d9-e273-3d9000ee74f0"
      },
      "source": [
        "# increase weight for pos label for data imbalance\n",
        "pos_weight = ((df_train['critical'] == 0).sum() / (df_train['critical'] == 1).sum())\n",
        "pos_weight = torch.Tensor([pos_weight.item()])\n",
        "print(pos_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([9.6657])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_abThXlSr6n"
      },
      "source": [
        "## Training and validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwXCoj9_h1hY"
      },
      "source": [
        "Link for the AdamW optimizer and the learning rate scheduler :\n",
        "https://huggingface.co/transformers/main_classes/optimizer_schedules.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZWGPomoryxy",
        "outputId": "9af5b903-966c-4277-b99e-1faddf9458bb"
      },
      "source": [
        "#  Set all seeds to make reproducible results\n",
        "set_seed(1)\n",
        "\n",
        "# Creating instances of training and validation set\n",
        "print(\"Reading training data...\")\n",
        "train_set = CustomDataset(df_train, maxlen, bert_model_src, bert_model_mt)\n",
        "print(\"Reading validation data...\")\n",
        "val_set = CustomDataset(df_val, maxlen, bert_model_src, bert_model_mt)\n",
        "# Creating instances of training and validation dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size=bs, num_workers=5)\n",
        "val_loader = DataLoader(val_set, batch_size=bs, num_workers=5)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = SentencePairClassifier(bert_model_src, bert_model_mt, freeze_bert=freeze_bert)\n",
        "if torch.cuda.device_count() > 1:  # if multiple GPUs\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    net = nn.DataParallel(net)\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
        "opti = AdamW(net.parameters(), lr=lr, weight_decay=1e-2)\n",
        "num_warmup_steps = 0 # The number of steps for the warmup phase.\n",
        "num_training_steps = epochs * len(train_loader)  # The total number of training steps\n",
        "t_total = (len(train_loader) // iters_to_accumulate) * epochs  # Necessary to take into account Gradient accumulation\n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)\n",
        "\n",
        "train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading training data...\n",
            "Reading validation data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            " 20%|█▉        | 121/607 [00:26<01:44,  4.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 121/607 of epoch 1 complete. Loss : 0.5924404476546059 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 243/607 [00:54<01:19,  4.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 242/607 of epoch 1 complete. Loss : 0.61461981687664 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 363/607 [01:21<00:53,  4.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 363/607 of epoch 1 complete. Loss : 0.5719453309439431 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 485/607 [01:48<00:26,  4.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 484/607 of epoch 1 complete. Loss : 0.6685479408945919 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 605/607 [02:16<00:00,  4.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 605/607 of epoch 1 complete. Loss : 0.5604158216271519 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 607/607 [02:16<00:00,  4.44it/s]\n",
            "100%|██████████| 32/32 [00:02<00:00, 11.01it/s]\n",
            "  0%|          | 0/607 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 complete! Validation Loss : 1.2318099504336715\n",
            "Best validation loss improved from inf to 1.2318099504336715\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 121/607 [00:28<01:48,  4.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 121/607 of epoch 2 complete. Loss : 0.520083511048112 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 243/607 [00:56<01:21,  4.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 242/607 of epoch 2 complete. Loss : 0.5296328578852425 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 363/607 [01:24<00:55,  4.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 363/607 of epoch 2 complete. Loss : 0.4836163844697732 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 485/607 [01:52<00:27,  4.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 484/607 of epoch 2 complete. Loss : 0.5926407634719344 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 605/607 [02:20<00:00,  4.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 605/607 of epoch 2 complete. Loss : 0.48757112605020037 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 607/607 [02:21<00:00,  4.30it/s]\n",
            "100%|██████████| 32/32 [00:02<00:00, 10.97it/s]\n",
            "  0%|          | 0/607 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 complete! Validation Loss : 1.2364204628393054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 121/607 [00:28<01:49,  4.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 121/607 of epoch 3 complete. Loss : 0.4213192188296436 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 243/607 [00:57<01:22,  4.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 242/607 of epoch 3 complete. Loss : 0.4092986031997302 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 363/607 [01:25<00:55,  4.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 363/607 of epoch 3 complete. Loss : 0.37838239462907647 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 485/607 [01:53<00:27,  4.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 484/607 of epoch 3 complete. Loss : 0.44762896062914004 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 605/607 [02:21<00:00,  4.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 605/607 of epoch 3 complete. Loss : 0.36670761900253535 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 607/607 [02:22<00:00,  4.27it/s]\n",
            "100%|██████████| 32/32 [00:02<00:00, 10.97it/s]\n",
            "  0%|          | 0/607 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 complete! Validation Loss : 1.4917262040544301\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 121/607 [00:28<01:50,  4.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 121/607 of epoch 4 complete. Loss : 0.30222080293888887 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 243/607 [00:57<01:22,  4.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 242/607 of epoch 4 complete. Loss : 0.2844176034727865 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 363/607 [01:25<00:55,  4.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 363/607 of epoch 4 complete. Loss : 0.2558854351605266 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 485/607 [01:53<00:27,  4.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 484/607 of epoch 4 complete. Loss : 0.3247256304237468 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 605/607 [02:21<00:00,  4.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 605/607 of epoch 4 complete. Loss : 0.24658464003077224 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 607/607 [02:22<00:00,  4.27it/s]\n",
            "100%|██████████| 32/32 [00:02<00:00, 11.01it/s]\n",
            "  0%|          | 0/607 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 complete! Validation Loss : 1.6381291340803728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 121/607 [00:28<01:50,  4.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 121/607 of epoch 5 complete. Loss : 0.19670346049853593 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 243/607 [00:57<01:22,  4.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 242/607 of epoch 5 complete. Loss : 0.18304133332095857 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 363/607 [01:25<00:55,  4.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 363/607 of epoch 5 complete. Loss : 0.19062894401102026 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 485/607 [01:53<00:27,  4.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 484/607 of epoch 5 complete. Loss : 0.2651115078017239 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 605/607 [02:21<00:00,  4.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 605/607 of epoch 5 complete. Loss : 0.20711439416920843 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 607/607 [02:22<00:00,  4.27it/s]\n",
            "100%|██████████| 32/32 [00:02<00:00, 10.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 complete! Validation Loss : 1.6235678367083892\n",
            "The model has been saved in models/japanese_lr_1e-05_val_loss_1.23181_ep_1.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw2sOrIvCEZz"
      },
      "source": [
        "You can download the model saved in the folder \"models\" by browsing the files on the left of the colab notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f4zThMtvqC1",
        "outputId": "85fea158-aea8-46cd-9a52-d8da668df1c4"
      },
      "source": [
        "# If you encounter a CUDA out of memory error: \n",
        "# - uncomment the kill command, run the \"kill\" command (and comment it)\n",
        "# - reduce the batch size\n",
        "# - then run all cells from the begining \n",
        "\n",
        "# If you get an ugly print of tqdm (all iterations are showed), follow the above first and last steps\n",
        "\n",
        "printm()\n",
        "# !kill -9 -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 11.5 GB  | Proc size: 6.1 GB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDBtVu7JSbUK"
      },
      "source": [
        "## Prediction and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWoWiw6MlPm-",
        "outputId": "0c091254-039c-4c31-b597-51b45d6af023"
      },
      "source": [
        "path_to_output_file = 'results/output_japanese.txt'\n",
        "\n",
        "print(\"Reading test data...\")\n",
        "test_set = CustomDataset(df_test, maxlen, bert_model_src, bert_model_mt)\n",
        "test_loader = DataLoader(test_set, batch_size=bs, num_workers=5)\n",
        "\n",
        "model = net\n",
        "print(\"Predicting on test data...\")\n",
        "test_prediction(net=model, device=device, dataloader=test_loader, with_labels=True,  # set the with_labels parameter to False if your want to get predictions on a dataset without labels\n",
        "                result_file=path_to_output_file)\n",
        "print()\n",
        "print(\"Predictions are available in : {}\".format(path_to_output_file))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading test data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\r  0%|          | 0/84 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting on test data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 84/84 [00:06<00:00, 12.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Predictions are available in : results/output_japanese.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCVAtClcC1qT"
      },
      "source": [
        "You can download the predictions saved in the folder \"results\" by browsing the files on the left of the colab notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JYwEPtrlBFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02cf39d8-edb9-4dc8-d17b-a45a48203ef3"
      },
      "source": [
        "path_to_output_file = 'results/output_japanese.txt'  # path to the file with prediction probabilities\n",
        "\n",
        "labels_test = df_test['critical']  # true labels\n",
        "\n",
        "probs_test = pd.read_csv(path_to_output_file, header=None)[0]  # prediction probabilities\n",
        "preds_test = get_pred_from_prob(labels_test, probs_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.433105, F-Score=0.331\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LGJRzdN7UOT"
      },
      "source": [
        "Link for the threshold choice problem : https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlXNt2UbVnJH",
        "outputId": "23e8acb0-9293-4e14-ea7b-ad8e40127777"
      },
      "source": [
        "evaluate_pred_test(labels_test, preds_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----Evaluation-----\n",
            "TP: 47, TN: 762, FP: 141, FN: 49\n",
            "F1:  0.33098591549295775\n",
            "Precision:  0.25\n",
            "Recall:  0.4895833333333333\n",
            "Accuracy:  0.8098098098098098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz6D-QLoJK1B"
      },
      "source": [
        "# For English-Chinese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS6mlIj7JS2C"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARK49WjRKeCa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "5db99e98-692a-43e2-c12b-d78b9a726660"
      },
      "source": [
        "df_train, df_val, df_test = dataset_splitting('en-zh')\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set:  (6515, 7)\n",
            "Validation set:  (343, 7)\n",
            "Test set: (999, 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>src</th>\n",
              "      <th>mt</th>\n",
              "      <th>list_scores</th>\n",
              "      <th>avg_scores</th>\n",
              "      <th>critical</th>\n",
              "      <th>language_pair</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4082</td>\n",
              "      <td>Tylototriton or Tylotriton? I'm confused - is ...</td>\n",
              "      <td>泰 洛特 里顿 还是 泰 洛特 里顿 ? 我 很 困惑 , 是 泰 洛特 里顿 还是 泰 洛...</td>\n",
              "      <td>[1, 0, 1]</td>\n",
              "      <td>ERR</td>\n",
              "      <td>1</td>\n",
              "      <td>en-zh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5608</td>\n",
              "      <td>In any case, the articles be written such that...</td>\n",
              "      <td>无论如何 , 条款 都 应 写成 这样 , 使 每个 军队 的 使用 条件 都 得到 充分 ...</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0</td>\n",
              "      <td>en-zh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3517</td>\n",
              "      <td>Yes, I am on the list also. Maybe you can get ...</td>\n",
              "      <td>是 的 , 我 也 在 名单 上 。 也许 你 可以 和 他 的 一些 成员 联系 , 就 ...</td>\n",
              "      <td>[3, 0, 0]</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0</td>\n",
              "      <td>en-zh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9744</td>\n",
              "      <td>Dennis, stop using the discussion page for you...</td>\n",
              "      <td>丹尼斯 , 不要 再用 讨论 页 来 讨论 你 对 纽曼 的 挑衅 .</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0</td>\n",
              "      <td>en-zh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9989</td>\n",
              "      <td>There has been a POV template in this article ...</td>\n",
              "      <td>在 这个 文章 里 已有近 三年 的 POV 模板 , 但 没有 在 谈话 页 上 。 也许...</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0</td>\n",
              "      <td>en-zh</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ... language_pair\n",
              "0  4082  ...         en-zh\n",
              "1  5608  ...         en-zh\n",
              "2  3517  ...         en-zh\n",
              "3  9744  ...         en-zh\n",
              "4  9989  ...         en-zh\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNEhvnYdKpkr"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu1wnUHlKoEl"
      },
      "source": [
        "model_name = \"chinese\"\n",
        "bert_model_src = \"bert-base-uncased\" #english bert model\n",
        "bert_model_mt = \"bert-base-chinese\" #chinese bert model\n",
        "freeze_bert = False  # if True, freeze the encoder weights and only update the classification layer weights\n",
        "maxlen = 128  # 75% below\n",
        "bs = 12  # batch size\n",
        "iters_to_accumulate = 2  # the gradient accumulation adds gradients over an effective batch of size : bs * iters_to_accumulate. If set to \"1\", you get the usual batch size\n",
        "lr = 1e-5 # learning rate\n",
        "epochs = 5  # number of training epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97CZsbnjMb_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c13596-56e7-4f48-d9f8-846c2944dce3"
      },
      "source": [
        "# increase weight for pos label for data imbalance\n",
        "pos_weight = ((df_train['critical'] == 0).sum() / (df_train['critical'] == 1).sum())\n",
        "pos_weight = torch.Tensor([pos_weight.item()])\n",
        "print(pos_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.1695])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svy5Ke9aMllu"
      },
      "source": [
        "## Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru0mBtFcMks8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4ddb4c518625475cb2992a8ba4026b9d",
            "ea5cb9ab00434308b4ce22f25eb89233",
            "b346672f1c9644bfbeb0eb61116bed7d",
            "a06f65fad4cd44af8e45c9ee680815db",
            "31e2a2644c1d4ba4825f9c6372203d22",
            "d1f6f48dbfb84e8cbb6fd1d3a15a332d",
            "1bc1f5029bbe45ef85a14de1e87de886",
            "d9e700da67614137a8801d3d55925465",
            "8660c8b8100f4480bee53279ebbd1f91",
            "19137ca3f4fd4b0ca4c69f7770a915a6",
            "e4a509729faa480a84d961e0c4d19c56",
            "8bc5a269714d4ca1b8bb24178738309f",
            "a9fb235d84fe40788539dfad041c469d",
            "d971ece6b4d341aabc96ae3e1ca47304",
            "3e12d226a1764ec79b1e55f010503a41",
            "3a244873692e403c9225bef7d20a94d9",
            "12c505343133406f877f9651d1b3a320",
            "32a66474599b475dbc249765caf49106",
            "5f74cad407a646eaa8b3ebc27a755e50",
            "93d5331bedd84e6abebccdce362bc9d4",
            "216818fc6ca34f76a3028514f1537f27",
            "1933c73861074406a0b45020f7dbbb0b",
            "c1267be3b8c44548a42c3d82d3d65be2",
            "5a692c030ca14964a39de2dda5ceaa9e"
          ]
        },
        "outputId": "d94b4918-0176-475e-a9ab-cf976342f6d6"
      },
      "source": [
        "#  Set all seeds to make reproducible results\n",
        "set_seed(1)\n",
        "\n",
        "# Creating instances of training and validation set\n",
        "print(\"Reading training data...\")\n",
        "train_set = CustomDataset(df_train, maxlen, bert_model_src, bert_model_mt)\n",
        "print(\"Reading validation data...\")\n",
        "val_set = CustomDataset(df_val, maxlen, bert_model_src, bert_model_mt)\n",
        "# Creating instances of training and validation dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size=bs, num_workers=5)\n",
        "val_loader = DataLoader(val_set, batch_size=bs, num_workers=5)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = SentencePairClassifier(bert_model_src, bert_model_mt, freeze_bert=freeze_bert)\n",
        "if torch.cuda.device_count() > 1:  # if multiple GPUs\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    net = nn.DataParallel(net)\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
        "opti = AdamW(net.parameters(), lr=lr, weight_decay=1e-2)\n",
        "num_warmup_steps = 0 # The number of steps for the warmup phase.\n",
        "num_training_steps = epochs * len(train_loader)  # The total number of training steps\n",
        "t_total = (len(train_loader) // iters_to_accumulate) * epochs  # Necessary to take into account Gradient accumulation\n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)\n",
        "\n",
        "train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading training data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ddb4c518625475cb2992a8ba4026b9d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=624.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8660c8b8100f4480bee53279ebbd1f91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Reading validation data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12c505343133406f877f9651d1b3a320",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411577189.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 109/543 [00:23<01:32,  4.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 108/543 of epoch 1 complete. Loss : 0.5746423902886885 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 217/543 [00:47<01:09,  4.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 216/543 of epoch 1 complete. Loss : 0.5584069082030544 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 325/543 [01:11<00:46,  4.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 324/543 of epoch 1 complete. Loss : 0.5473480195634894 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 433/543 [01:35<00:23,  4.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 432/543 of epoch 1 complete. Loss : 0.528438818399553 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 541/543 [01:59<00:00,  4.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 540/543 of epoch 1 complete. Loss : 0.5363861107163959 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 543/543 [01:59<00:00,  4.53it/s]\n",
            "100%|██████████| 29/29 [00:02<00:00, 11.43it/s]\n",
            "  0%|          | 0/543 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 complete! Validation Loss : 1.0282572918924793\n",
            "Best validation loss improved from inf to 1.0282572918924793\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 109/543 [00:24<01:35,  4.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 108/543 of epoch 2 complete. Loss : 0.4919968429538939 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 217/543 [00:49<01:12,  4.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 216/543 of epoch 2 complete. Loss : 0.5086771219416901 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 325/543 [01:13<00:48,  4.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 324/543 of epoch 2 complete. Loss : 0.4460193612785251 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 433/543 [01:38<00:24,  4.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 432/543 of epoch 2 complete. Loss : 0.457309630320028 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 541/543 [02:03<00:00,  4.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 540/543 of epoch 2 complete. Loss : 0.453517562813229 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 543/543 [02:03<00:00,  4.38it/s]\n",
            "100%|██████████| 29/29 [00:02<00:00, 11.10it/s]\n",
            "  0%|          | 0/543 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 complete! Validation Loss : 1.0236627685612645\n",
            "Best validation loss improved from 1.0282572918924793 to 1.0236627685612645\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 109/543 [00:25<01:37,  4.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 108/543 of epoch 3 complete. Loss : 0.3994307003363415 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 217/543 [00:50<01:12,  4.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 216/543 of epoch 3 complete. Loss : 0.39024090787602794 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 325/543 [01:15<00:48,  4.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 324/543 of epoch 3 complete. Loss : 0.3174380586930999 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 433/543 [01:40<00:24,  4.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 432/543 of epoch 3 complete. Loss : 0.32665915442285715 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 541/543 [02:05<00:00,  4.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 540/543 of epoch 3 complete. Loss : 0.3219937146813781 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 543/543 [02:05<00:00,  4.32it/s]\n",
            "100%|██████████| 29/29 [00:02<00:00, 11.02it/s]\n",
            "  0%|          | 0/543 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 complete! Validation Loss : 1.1789402072799617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 109/543 [00:25<01:37,  4.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 108/543 of epoch 4 complete. Loss : 0.2820303007201464 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 217/543 [00:50<01:12,  4.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 216/543 of epoch 4 complete. Loss : 0.2638240935349906 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 325/543 [01:15<00:49,  4.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 324/543 of epoch 4 complete. Loss : 0.2045385887570403 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 433/543 [01:40<00:24,  4.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 432/543 of epoch 4 complete. Loss : 0.20773854251537058 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 541/543 [02:05<00:00,  4.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 540/543 of epoch 4 complete. Loss : 0.19794288591516238 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 543/543 [02:06<00:00,  4.31it/s]\n",
            "100%|██████████| 29/29 [00:02<00:00, 10.97it/s]\n",
            "  0%|          | 0/543 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 complete! Validation Loss : 1.4725263740482002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 109/543 [00:25<01:37,  4.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 108/543 of epoch 5 complete. Loss : 0.19969332794210426 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 217/543 [00:50<01:13,  4.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 216/543 of epoch 5 complete. Loss : 0.15889315024294234 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 325/543 [01:15<00:48,  4.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 324/543 of epoch 5 complete. Loss : 0.14190769559462313 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 433/543 [01:40<00:24,  4.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 432/543 of epoch 5 complete. Loss : 0.1582438413709126 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 541/543 [02:05<00:00,  4.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 540/543 of epoch 5 complete. Loss : 0.15900073067664547 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 543/543 [02:05<00:00,  4.31it/s]\n",
            "100%|██████████| 29/29 [00:02<00:00, 10.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 complete! Validation Loss : 1.6629903331912796\n",
            "The model has been saved in models/chinese_lr_1e-05_val_loss_1.02366_ep_2.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3NHbNyrMr3H"
      },
      "source": [
        "# If you encounter a CUDA out of memory error: \n",
        "# - uncomment the kill command, run the \"kill\" command (and comment it)\n",
        "# - reduce the batch size\n",
        "# - then run all cells from the begining \n",
        "\n",
        "# If you get an ugly print of tqdm (all iterations are showed), follow the above first and last steps\n",
        "\n",
        "printm()\n",
        "# !kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMrBzUCzMv-n"
      },
      "source": [
        "## Prediction and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81t-indqMytA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6dbc3d-093f-478d-bc9b-0b685114f483"
      },
      "source": [
        "path_to_output_file = 'results/output_chinese.txt'\n",
        "\n",
        "print(\"Reading test data...\")\n",
        "test_set = CustomDataset(df_test, maxlen, bert_model_src, bert_model_mt)\n",
        "test_loader = DataLoader(test_set, batch_size=bs, num_workers=5)\n",
        "\n",
        "model = net\n",
        "print(\"Predicting on test data...\")\n",
        "test_prediction(net=model, device=device, dataloader=test_loader, with_labels=True,  # set the with_labels parameter to False if your want to get predictions on a dataset without labels\n",
        "                result_file=path_to_output_file)\n",
        "print()\n",
        "print(\"Predictions are available in : {}\".format(path_to_output_file))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading test data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\r  0%|          | 0/84 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting on test data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 84/84 [00:06<00:00, 12.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Predictions are available in : results/output_chinese.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfFKNA7gM2GC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b7952a-dfed-4ff7-b68d-533d07c18670"
      },
      "source": [
        "path_to_output_file = 'results/output_chinese.txt'  # path to the file with prediction probabilities\n",
        "\n",
        "labels_test = df_test['critical']  # true labels\n",
        "\n",
        "probs_test = pd.read_csv(path_to_output_file, header=None)[0]  # prediction probabilities\n",
        "preds_test = get_pred_from_prob(labels_test, probs_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.131714, F-Score=0.334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VgwN1NYM5Cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b6b3c3-c570-413b-8a8b-d1f4feebe437"
      },
      "source": [
        "evaluate_pred_test(labels_test, preds_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----Evaluation-----\n",
            "TP: 83, TN: 585, FP: 273, FN: 58\n",
            "F1:  0.33400402414486924\n",
            "Precision:  0.23314606741573032\n",
            "Recall:  0.5886524822695035\n",
            "Accuracy:  0.6686686686686687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHZfpy7XaUmu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}